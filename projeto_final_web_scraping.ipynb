{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "802f65fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_period_dtype\n",
    "\n",
    "import asyncio\n",
    "from typing import List, Dict, Optional\n",
    "from playwright.async_api import async_playwright, Page\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import datetime as dt\n",
    "from typing import Optional, Tuple\n",
    "import requests\n",
    "import duckdb\n",
    "\n",
    "import asyncio, csv, re\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin\n",
    "from playwright.async_api import async_playwright, Page\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e959f",
   "metadata": {},
   "source": [
    "# üß† Projeto: Enriquecimento de Base Anal√≠tica com Web Scraping e API Financeira\n",
    "\n",
    "## üéØ Contexto\n",
    "\n",
    "Uma **fintech de investimentos** precisa enriquecer sua base anal√≠tica com informa√ß√µes externas do mercado para apoiar decis√µes estrat√©gicas.\n",
    "Como Engenheira de Dados, foi desenvolvido um **pipeline de dados** que coleta informa√ß√µes p√∫blicas de **not√≠cias** e **s√©ries financeiras**, armazena localmente em um **banco DuckDB**, e permite posterior explora√ß√£o via SQL e dashboards.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© Objetivo\n",
    "\n",
    "Construir um pipeline completo de **coleta, transforma√ß√£o e carga (ETL)** que una:\n",
    "\n",
    "* **Web Scraping** de not√≠cias econ√¥micas e geopol√≠ticas (BBC News);\n",
    "* **API P√∫blica** de dados financeiros (FRED e CoinGecko);\n",
    "* **Integra√ß√£o anal√≠tica** em banco local **DuckDB**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Stack Utilizada\n",
    "\n",
    "| Etapa         | Tecnologia                        | Descri√ß√£o                                          |\n",
    "| ------------- | --------------------------------- | -------------------------------------------------- |\n",
    "| Coleta Web    | `Playwright` + `asyncio`          | Scraping ass√≠ncrono de p√°ginas de not√≠cias da BBC  |\n",
    "| Coleta API    | `requests`, `pandas`              | Consumo de APIs FRED (Federal Reserve) e CoinGecko |\n",
    "| Armazenamento | `DuckDB`                          | Banco anal√≠tico local com tr√™s tabelas             |\n",
    "| Ambiente      | `Python 3.9+`, `Jupyter Notebook` | Execu√ß√£o e an√°lise                                 |\n",
    "| Persist√™ncia  | `.duckdb`, `.parquet`, `.csv`     | Formatos intermedi√°rios                            |\n",
    "\n",
    "---\n",
    "\n",
    "## üåê Fontes de Dados\n",
    "\n",
    "### üîπ Not√≠cias (Web Scraping ‚Äì BBC News)\n",
    "\n",
    "* Fonte: [BBC News ‚Äì US-Canada](https://www.bbc.com/news/us-canada)\n",
    "* Coletadas **100 not√≠cias** contendo t√≠tulo, resumo, link e data de coleta.\n",
    "* Campos armazenados:\n",
    "\n",
    "  ```\n",
    "  ['title', 'url', 'summary', 'collected_at']\n",
    "  ```\n",
    "* Objetivo: capturar contexto geopol√≠tico e eventos com impacto em mercados.\n",
    "\n",
    "### üîπ S√©ries Financeiras (APIs P√∫blicas)\n",
    "\n",
    "| Fonte     | S√©rie          | Descri√ß√£o                                   | Per√≠odo  |\n",
    "| --------- | -------------- | ------------------------------------------- | -------- |\n",
    "| FRED      | `DCOILBRENTEU` | Pre√ßo di√°rio do petr√≥leo Brent (USD/barril) | 6+ meses |\n",
    "| FRED      | `DEXUSUK`      | Taxa USD/GBP (invertida para GBP/USD)       | 6+ meses |\n",
    "| CoinGecko | `BTC/USD`      | Cota√ß√£o di√°ria do Bitcoin                   | 6+ meses |\n",
    "\n",
    "Os dados foram padronizados em base di√°ria cont√≠nua, com c√°lculo de retornos em janelas de 1, 3 e 5 dias (`r1`, `r3`, `r5`).\n",
    "\n",
    "---\n",
    "\n",
    "## üóÑÔ∏è Modelagem de Dados no DuckDB\n",
    "\n",
    "### Tabelas criadas:\n",
    "\n",
    "| Tabela          | Descri√ß√£o                       | Principais Campos                          |\n",
    "| --------------- | ------------------------------- | ------------------------------------------ |\n",
    "| **prices**      | S√©ries hist√≥ricas dos ativos    | `instr`, `date`, `close`, `r1`, `r3`, `r5` |\n",
    "| **news_bbc**    | Not√≠cias coletadas via scraping | `title`, `url`, `summary`, `collected_at`  |\n",
    "| **instruments** | Metadados dos instrumentos      | `instr_id`, `symbol`, `name`, `class`      |\n",
    "\n",
    "```sql\n",
    "-- Exemplo de schema no DuckDB\n",
    "DESCRIBE prices;\n",
    "DESCRIBE news_bbc;\n",
    "DESCRIBE instruments;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Resultados\n",
    "\n",
    "* **100 not√≠cias** coletadas da BBC News.\n",
    "* **3 instrumentos** (Brent, GBP/USD, BTC/USD) com **211 dias** de dados cada.\n",
    "* **3 tabelas anal√≠ticas** armazenadas no DuckDB (`prices`, `news_bbc`, `instruments`).\n",
    "* Pipeline totalmente reprodut√≠vel e modular, pronto para expans√£o com novos t√≥picos ou ativos.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Estrutura Final\n",
    "\n",
    "```\n",
    "üìÇ projeto_etl_fintech/\n",
    "‚îÇ\n",
    "‚îú‚îÄ‚îÄ market.duckdb                 # Banco anal√≠tico local\n",
    "‚îú‚îÄ‚îÄ prices.parquet                # Dados de pre√ßos\n",
    "‚îú‚îÄ‚îÄ bbc_israel_gaza_war.csv       # Not√≠cias coletadas\n",
    "‚îú‚îÄ‚îÄ etl_pipeline.ipynb            # Notebook principal\n",
    "‚îî‚îÄ‚îÄ requirements.txt              # Depend√™ncias fixas\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclus√£o\n",
    "\n",
    "O projeto integra dados n√£o estruturados (not√≠cias) e estruturados (s√©ries econ√¥micas), simulando um fluxo real de engenharia de dados.\n",
    "Com as tabelas organizadas no DuckDB, √© poss√≠vel executar consultas SQL r√°pidas e realizar an√°lises temporais sobre o impacto de eventos geopol√≠ticos nos ativos financeiros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98c8b1",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d5c52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUCKDB_PATH = os.getenv(\"DUCKDB_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed4ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Configs\n",
    "# =========================\n",
    "# 100 √∫ltimas not√≠cias do BBC US & Canada\n",
    "\n",
    "START_URL = os.getenv(\"NEWS_SOURCE\")\n",
    "TARGET = 100\n",
    "OUTCSV = \"bbc_us_canada_latest_updates.csv\"\n",
    "BASE = \"https://www.bbc.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9d31a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Configs\n",
    "# =========================\n",
    "# Per√≠odo alvo (>= 6 meses); pego ~210 dias\\\n",
    "\n",
    "END = dt.date.today()\n",
    "START = END - dt.timedelta(days=210)  # ~7 meses\n",
    "\n",
    "FRED_API_KEY = os.getenv(\"FRED_API_KEY\")  # .env\n",
    "FRED_BASE = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "FRED_SERIES = {\n",
    "    \"BRENT\": \"DCOILBRENTEU\",  # Brent Europe, di√°rio\n",
    "    \"GBPUSD\": \"DEXUSUK\",      # Taxa USD/GBP di√°ria \n",
    "}\n",
    "\n",
    "COINGECKO_BASE = \"https://api.coingecko.com/api/v3\"\n",
    "COINGECKO_COIN = \"bitcoin\"\n",
    "COINGECKO_VS = \"usd\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ab16f4",
   "metadata": {},
   "source": [
    "## Web scraping de not√≠cias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99a8a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def abs_url(href): return urljoin(BASE, href or \"\")\n",
    "\n",
    "async def accept_cookies(page: Page):\n",
    "    for sel in (\n",
    "        '[data-testid=\"cookie-banner\"] button:has-text(\"Accept\")',\n",
    "        'button:has-text(\"I Agree\")','button:has-text(\"Agree\")','#bbccookies-continue-button',\n",
    "    ):\n",
    "        b = page.locator(sel).first\n",
    "        if await b.count() and await b.is_visible():\n",
    "            await b.click(); break\n",
    "\n",
    "async def wait_heading(page: Page):\n",
    "    await page.wait_for_selector('h2[data-testid=\"alaska-title\"]', timeout=15000)\n",
    "\n",
    "async def extract_latest_updates_on_page(page: Page):\n",
    "    # Extrator geom√©trico: pega links /news/ VISUALMENTE entre o heading e a pagina√ß√£o\n",
    "    js = \"\"\"\n",
    "    () => {\n",
    "      const BASE = 'https://www.bbc.com';\n",
    "      const head = document.querySelector('h2[data-testid=\"alaska-title\"]');\n",
    "      if (!head) return {items: [], debug: {reason: 'no heading'}};\n",
    "      const headBottom = head.getBoundingClientRect().bottom + window.scrollY;\n",
    "\n",
    "      // tenta achar a barra de pagina√ß√£o (nav ou container com bot√µes 1,2,3)\n",
    "      let pag = document.querySelector('nav[aria-label*=\"Pagination\" i]') ||\n",
    "                Array.from(document.querySelectorAll('nav, div, section'))\n",
    "                  .find(n => /Go to page/i.test(n.textContent||'') || /\\b1\\b.*\\b2\\b.*\\b3\\b/.test(n.textContent||''));\n",
    "      let pagTop = Infinity;\n",
    "      if (pag) pagTop = pag.getBoundingClientRect().top + window.scrollY;\n",
    "\n",
    "      const links = Array.from(document.querySelectorAll('a[href*=\"/news/\"]'));\n",
    "      const filtered = [];\n",
    "\n",
    "      for (const a of links) {\n",
    "        const r = a.getBoundingClientRect();\n",
    "        const y = r.top + window.scrollY;\n",
    "        if (y > headBottom && y < pagTop) {\n",
    "          // t√≠tulo\n",
    "          let title = (a.querySelector('h3,h2')?.textContent || a.textContent || '').trim().replace(/\\s+/g,' ');\n",
    "          if (!title || title.length < 5) continue;\n",
    "\n",
    "          // item container p/ achar resumo/time\n",
    "          const container = a.closest('li, article, div[role=\"listitem\"], div, section') || a;\n",
    "          const p = container.querySelector('p');\n",
    "          const time = container.querySelector('time');\n",
    "\n",
    "          const summary = (p?.textContent || '').trim().replace(/\\s+/g,' ');\n",
    "          const rel = (time?.textContent || '').trim();\n",
    "\n",
    "          try {\n",
    "            const url = new URL(a.getAttribute('href'), BASE).toString();\n",
    "            filtered.push({title, url, summary, relative_date: rel});\n",
    "          } catch {}\n",
    "        }\n",
    "      }\n",
    "\n",
    "      // dedupe por URL e remove duplicados do mesmo t√≠tulo\n",
    "      const seen = new Set();\n",
    "      const items = [];\n",
    "      for (const it of filtered) {\n",
    "        if (!seen.has(it.url)) { seen.add(it.url); items.push(it); }\n",
    "      }\n",
    "      return {items, debug: {headBottom, pagTop, totalLinks: links.length, kept: items.length}};\n",
    "    }\n",
    "    \"\"\"\n",
    "    res = await page.evaluate(js)\n",
    "    items = res[\"items\"]\n",
    "    iso = datetime.now().isoformat()\n",
    "    for it in items: it[\"collected_at\"] = iso\n",
    "    print(f'‚Üí between heading/pagination: {res[\"debug\"][\"kept\"]} of {res[\"debug\"][\"totalLinks\"]}')\n",
    "    return items\n",
    "\n",
    "async def get_max_page(page: Page) -> int:\n",
    "    # l√™ todos \"Go to page N\" e pega o maior\n",
    "    nums = set()\n",
    "    btns = page.locator('button[aria-label^=\"Go to page \"]')\n",
    "    for i in range(await btns.count()):\n",
    "        lbl = await btns.nth(i).get_attribute(\"aria-label\")\n",
    "        m = re.search(r\"(\\d+)$\", lbl or \"\")\n",
    "        if m: nums.add(int(m.group(1)))\n",
    "    # fallback: n√∫meros vis√≠veis no paginador\n",
    "    nav = page.locator(\"nav\").filter(has_text=re.compile(r\"\\b1\\b\"))\n",
    "    if await nav.count():\n",
    "        txt = \" \".join(await nav.first.all_text_contents())\n",
    "        for n in re.findall(r\"\\b\\d+\\b\", txt):\n",
    "            nums.add(int(n))\n",
    "    return max(nums) if nums else 1\n",
    "\n",
    "async def click_page_n(page: Page, n: int) -> bool:\n",
    "    # garante que o paginador est√° na tela\n",
    "    await page.mouse.wheel(0, 99999)\n",
    "    # 1) for√ßa o clique via JS no aria-label \"Go to page n\"\n",
    "    ok = await page.evaluate(\"\"\"\n",
    "    (n) => {\n",
    "      const byAria = Array.from(document.querySelectorAll('button[aria-label^=\"Go to page \"]'))\n",
    "        .find(b => (b.getAttribute('aria-label')||'').trim().endsWith(String(n)));\n",
    "      if (byAria) { byAria.click(); return true; }\n",
    "      // fallback por texto vis√≠vel = n\n",
    "      const byText = Array.from(document.querySelectorAll('nav button, button'))\n",
    "        .find(b => (b.textContent||'').trim() === String(n));\n",
    "      if (byText) { byText.click(); return true; }\n",
    "      return false;\n",
    "    }\n",
    "    \"\"\", n)\n",
    "    if ok:\n",
    "        await page.wait_for_load_state(\"domcontentloaded\")\n",
    "        await page.wait_for_timeout(900)\n",
    "        return True\n",
    "\n",
    "    # 2) fallback: clica no chevron \">\" (pr√≥xima)\n",
    "    chevron = page.locator('nav button[aria-label*=\"next\" i], nav button:has-text(\">\"), nav button:has-text(\"‚Ä∫\")').first\n",
    "    if await chevron.count():\n",
    "        await chevron.click()\n",
    "        await page.wait_for_load_state(\"domcontentloaded\")\n",
    "        await page.wait_for_timeout(900)\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "async def scrape_latest_updates(target: int = TARGET):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        context = await browser.new_context()\n",
    "        page = await context.new_page()\n",
    "        await page.goto(START_URL, timeout=60_000)\n",
    "        await accept_cookies(page)\n",
    "        await wait_heading(page)\n",
    "\n",
    "        results, seen = [], set()\n",
    "        page_no = 1\n",
    "        max_page = await get_max_page(page)\n",
    "\n",
    "        while len(results) < target and page_no <= max_page:\n",
    "            # rola um pouco p/ garantir render\n",
    "            await page.mouse.wheel(0, 2200); await asyncio.sleep(0.3)\n",
    "            batch = await extract_latest_updates_on_page(page)\n",
    "            print(f\"P√°gina {page_no} ‚Üí {len(batch)} itens\")\n",
    "            for it in batch:\n",
    "                if it[\"url\"] in seen: continue\n",
    "                seen.add(it[\"url\"]); results.append(it)\n",
    "                if len(results) >= target: break\n",
    "            if len(results) >= target: break\n",
    "            page_no += 1\n",
    "            if page_no > max_page: break\n",
    "            # leva o paginador ao viewport e clica no n√∫mero\n",
    "            await page.mouse.wheel(0, 9_999); await asyncio.sleep(0.2)\n",
    "            if not await click_page_n(page, page_no):\n",
    "                print(f\"‚ö†Ô∏è n√£o consegui clicar na p√°gina {page_no}\")\n",
    "                break\n",
    "\n",
    "        await browser.close()\n",
    "        return results[:target]\n",
    "\n",
    "async def save_csv(rows, path=OUTCSV):\n",
    "    cols = [\"title\",\"url\",\"summary\",\"relative_date\",\"collected_at\"]\n",
    "    with open(path,\"w\",newline=\"\",encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=cols); w.writeheader()\n",
    "        for r in rows: w.writerow({k:r.get(k,\"\") for k in cols})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e0b06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí between heading/pagination: 9 of 46\n",
      "P√°gina 1 ‚Üí 9 itens\n",
      "‚Üí between heading/pagination: 0 of 37\n",
      "P√°gina 2 ‚Üí 0 itens\n",
      "‚ö†Ô∏è n√£o consegui clicar na p√°gina 3\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Execu√ß√£o\n",
    "# =========================\n",
    "data = await scrape_latest_updates(100)\n",
    "await save_csv(data, OUTCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "261e9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b33ec03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   title          9 non-null      object\n",
      " 1   url            9 non-null      object\n",
      " 2   summary        9 non-null      object\n",
      " 3   relative_date  9 non-null      object\n",
      " 4   collected_at   9 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 492.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "news.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79213c74",
   "metadata": {},
   "source": [
    "### Persist√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12fc6d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x10dc9a4f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1) manter s√≥ as colunas com valor ---\n",
    "news = news[[\"title\", \"url\", \"summary\", \"collected_at\"]].copy()\n",
    "news[\"collected_at\"] = pd.to_datetime(news[\"collected_at\"], utc=True, errors=\"coerce\")\n",
    "news = news.drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
    "\n",
    "# --- 2) conectar ao banco local ---\n",
    "con = duckdb.connect(DUCKDB_PATH)\n",
    "\n",
    "# --- 3) criar a tabela de not√≠cias com apenas as colunas ---\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS news_bbc (\n",
    "    title         VARCHAR,\n",
    "    url           VARCHAR,\n",
    "    summary       VARCHAR,\n",
    "    collected_at  TIMESTAMP\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# --- 4) inserir os dados ---\n",
    "con.register(\"tmp_news\", news)\n",
    "con.execute(\"\"\"\n",
    "INSERT INTO news_bbc\n",
    "SELECT title, url, summary, collected_at\n",
    "FROM tmp_news;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657870c1",
   "metadata": {},
   "source": [
    "### Verifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9cead3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     n\n",
      "0  209\n",
      "                                               title  \\\n",
      "0    Businesses are running out of pennies in the US   \n",
      "1  SNAP benefits: When will the US government shu...   \n",
      "2  US judges say Trump administration must contin...   \n",
      "3  Top Republican rebuffs Trump calls to axe fili...   \n",
      "4  Watch: Pet monkey gets loose inside US Hallowe...   \n",
      "\n",
      "                                              url  \\\n",
      "0  https://www.bbc.com/news/articles/c20556ly45eo   \n",
      "1  https://www.bbc.com/news/articles/cew4gnyw8rlo   \n",
      "2  https://www.bbc.com/news/articles/cr433x9zqq4o   \n",
      "3  https://www.bbc.com/news/articles/c1d0qwx5z2vo   \n",
      "4    https://www.bbc.com/news/videos/c70jj362x9yo   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Find a penny, pick it up, then what? Now the U...   \n",
      "1  The programme helps 40 million low-income Amer...   \n",
      "2  In two separate rulings, US judges said the pl...   \n",
      "3  Ending the long-standing rule would allow Repu...   \n",
      "4  The owner of the acrobatic primate told police...   \n",
      "\n",
      "                collected_at  \n",
      "0 2025-10-31 16:46:15.506389  \n",
      "1 2025-10-31 16:46:15.506389  \n",
      "2 2025-10-31 16:46:15.506389  \n",
      "3 2025-10-31 16:46:15.506389  \n",
      "4 2025-10-31 16:46:15.506389  \n"
     ]
    }
   ],
   "source": [
    "# --- 5) checar resultado ---\n",
    "print(con.execute(\"SELECT COUNT(*) AS n FROM news_bbc\").df())\n",
    "print(con.execute(\"SELECT * FROM news_bbc LIMIT 5\").df())\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d354e45",
   "metadata": {},
   "source": [
    "## API com dados de petr√≥leo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9ee6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def _retry_get(url: str, params: dict = None, max_tries: int = 5, sleep_base: float = 1.0):\n",
    "    for i in range(max_tries):\n",
    "        r = requests.get(url, params=params, timeout=30)\n",
    "        if r.status_code == 200:\n",
    "            return r\n",
    "        time.sleep(sleep_base * (2**i))\n",
    "    r.raise_for_status()\n",
    "\n",
    "def _reindex_full_range(df: pd.DataFrame, start: dt.date, end: dt.date, date_col=\"date\", value_cols=None):\n",
    "    \"\"\"Garante cobertura di√°ria START‚ÜíEND com bfill+ffill.\"\"\"\n",
    "    if value_cols is None:\n",
    "        value_cols = [c for c in df.columns if c != date_col]\n",
    "    full = pd.DataFrame({\"date\": pd.date_range(start, end, freq=\"D\").date})\n",
    "    out = full.merge(df, on=\"date\", how=\"left\")\n",
    "    # Corrige tipos num√©ricos\n",
    "    for c in value_cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "        out[c] = out[c].bfill().ffill()  # preenche come√ßo e meio\n",
    "    return out\n",
    "\n",
    "def fetch_fred_series_strict(series_id, start: dt.date, end: dt.date, api_key: str) -> pd.DataFrame:\n",
    "    base = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "    params = {\n",
    "        \"series_id\": series_id,\n",
    "        \"api_key\": api_key,\n",
    "        \"file_type\": \"json\",\n",
    "        \"observation_start\": start.isoformat(),\n",
    "        \"observation_end\": end.isoformat(),\n",
    "    }\n",
    "    r = _retry_get(base, params=params)\n",
    "    data = r.json().get(\"observations\", [])\n",
    "    df = pd.DataFrame(data)[[\"date\", \"value\"]] if data else pd.DataFrame(columns=[\"date\",\"value\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"]).dt.date\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "    df = _reindex_full_range(df, start, end, value_cols=[\"value\"])\n",
    "    return df.rename(columns={\"value\": \"close\"})\n",
    "\n",
    "def fetch_coingecko_btc_strict(start: dt.date, end: dt.date, vs_currency=\"usd\") -> pd.DataFrame:\n",
    "    base = \"https://api.coingecko.com/api/v3/coins/bitcoin/market_chart\"\n",
    "    days = (end - start).days + 5\n",
    "    r = _retry_get(base, params={\"vs_currency\": vs_currency, \"days\": days})\n",
    "    js = r.json()\n",
    "    p = pd.DataFrame(js.get(\"prices\", []), columns=[\"ts_ms\", \"close\"])\n",
    "    if p.empty:\n",
    "        p = pd.DataFrame(columns=[\"date\", \"close\"])\n",
    "    else:\n",
    "        p[\"date\"] = pd.to_datetime(p[\"ts_ms\"], unit=\"ms\").dt.date\n",
    "        p = p.sort_values(\"ts_ms\").groupby(\"date\", as_index=False).tail(1)[[\"date\",\"close\"]]\n",
    "        p = p[(p[\"date\"] >= start) & (p[\"date\"] <= end)]\n",
    "    p = _reindex_full_range(p, start, end, value_cols=[\"close\"])\n",
    "    return p\n",
    "\n",
    "def ensure_min_6_months(df, start, end, date_col=\"date\"):\n",
    "    if df.empty:\n",
    "        raise AssertionError(\"DataFrame vazio.\")\n",
    "    span = (df[date_col].max() - df[date_col].min()).days\n",
    "    if span < 180:\n",
    "        raise AssertionError(f\"Menos de 6 meses: {span} dias.\")\n",
    "    # no m√°ximo 1% de buracos (ap√≥s reindex + bfill/ffill deve ser 0)\n",
    "    expected = set(pd.date_range(start, end, freq=\"D\").date)\n",
    "    got = set(df[date_col].values)\n",
    "    missing = expected - got\n",
    "    if len(missing) > len(expected) * 0.01:\n",
    "        raise AssertionError(f\"Muitas datas faltando ({len(missing)}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c33c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coletando de 2025-04-04 at√© 2025-10-31 (~210 dias)\n",
      "[OK] BRENT: 2025-04-04 ‚Üí 2025-10-31 | 211 linhas\n",
      "[OK] GBPUSD: 2025-04-04 ‚Üí 2025-10-31 | 211 linhas\n",
      "[OK] BTCUSD: 2025-04-04 ‚Üí 2025-10-31 | 211 linhas\n",
      "           date         close   instr\n",
      "0    2025-04-04     68.360000   BRENT\n",
      "1    2025-04-05     66.130000   BRENT\n",
      "2    2025-04-06     66.130000   BRENT\n",
      "422  2025-04-04  83163.987574  BTCUSD\n",
      "423  2025-04-05  83852.007654  BTCUSD\n",
      "424  2025-04-06  83595.885502  BTCUSD\n",
      "211  2025-04-04      0.773575  GBPUSD\n",
      "212  2025-04-05      0.785608  GBPUSD\n",
      "213  2025-04-06      0.785608  GBPUSD\n",
      "           date          close   instr\n",
      "208  2025-10-29      65.520000   BRENT\n",
      "209  2025-10-30      65.520000   BRENT\n",
      "210  2025-10-31      65.520000   BRENT\n",
      "630  2025-10-29  112950.348633  BTCUSD\n",
      "631  2025-10-30  110046.669258  BTCUSD\n",
      "632  2025-10-31  109553.033725  BTCUSD\n",
      "419  2025-10-29       0.751993  GBPUSD\n",
      "420  2025-10-30       0.751993  GBPUSD\n",
      "421  2025-10-31       0.751993  GBPUSD\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Execu√ß√£o\n",
    "# =========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Coletando de {START} at√© {END} (~{(END-START).days} dias)\")\n",
    "\n",
    "    # ---- FRED: Brent & DEXUSUK ----\n",
    "    brent = fetch_fred_series_strict(\"DCOILBRENTEU\", START, END, FRED_API_KEY)  # Brent\n",
    "    dex = fetch_fred_series_strict(\"DEXUSUK\", START, END, FRED_API_KEY)         # USD/GBP\n",
    "    gbpusd = dex.assign(close=lambda d: 1.0 / d[\"close\"]).copy()                # GBP/USD\n",
    "\n",
    "    # ---- CoinGecko: BTC/USD ----\n",
    "    btc = fetch_coingecko_btc_strict(START, END, \"usd\")\n",
    "\n",
    "    # ---- Valida√ß√£o ----\n",
    "    for name, df in [(\"BRENT\", brent), (\"GBPUSD\", gbpusd), (\"BTCUSD\", btc)]:\n",
    "        ensure_min_6_months(df, START, END)\n",
    "        print(f\"[OK] {name}: {df['date'].min()} ‚Üí {df['date'].max()} | {len(df)} linhas\")\n",
    "\n",
    "    # ---- Consolida para salvar ----\n",
    "    prices = pd.concat(\n",
    "        [\n",
    "            brent.assign(instr=\"BRENT\"),\n",
    "            gbpusd.assign(instr=\"GBPUSD\"),\n",
    "            btc.assign(instr=\"BTCUSD\"),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    ).sort_values([\"instr\", \"date\"])\n",
    "\n",
    "    print(prices.groupby(\"instr\").head(3))\n",
    "    print(prices.groupby(\"instr\").tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8264d8",
   "metadata": {},
   "source": [
    "### Persist√™ncia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b71b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(getattr(prices.index, \"dtype\", None), pd.PeriodDtype):\n",
    "    prices = prices.copy()\n",
    "    prices.index = prices.index.to_timestamp()           # para Timestamp\n",
    "    prices = prices.reset_index().rename(columns={\"index\":\"date\"})\n",
    "\n",
    "for c in prices.columns:\n",
    "    if isinstance(prices[c].dtype, pd.PeriodDtype):\n",
    "        prices[c] = prices[c].dt.to_timestamp()\n",
    "\n",
    "prices[\"date\"] = pd.to_datetime(prices[\"date\"]).dt.date   # date puro\n",
    "prices[\"instr\"] = prices[\"instr\"].astype(str)\n",
    "for c in [\"close\",\"r1\",\"r3\",\"r5\"]:\n",
    "    if c in prices:\n",
    "        prices[c] = pd.to_numeric(prices[c], errors=\"coerce\").astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a08abd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dados salvos na tabela 'prices' do banco market.duckdb\n"
     ]
    }
   ],
   "source": [
    "# salva em parquet (opcional)\n",
    "prices.to_parquet(\"prices.parquet\", index=False)\n",
    "\n",
    "# conecta ao banco local\n",
    "con = duckdb.connect(DUCKDB_PATH)\n",
    "\n",
    "# cria a tabela se n√£o existir\n",
    "con.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS prices;\n",
    "CREATE TABLE IF NOT EXISTS prices (\n",
    "    date DATE,\n",
    "    close DOUBLE,\n",
    "    instr VARCHAR\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# registra o DataFrame do pandas como uma \"view\" tempor√°ria\n",
    "con.register(\"tmp_prices\", prices)\n",
    "\n",
    "# insere os dados na tabela\n",
    "con.execute(\"\"\"\n",
    "INSERT INTO prices\n",
    "SELECT * FROM tmp_prices;\n",
    "\"\"\")\n",
    "\n",
    "# confirma e fecha\n",
    "con.close()\n",
    "print(\"‚úÖ Dados salvos na tabela 'prices' do banco market.duckdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37696ab6",
   "metadata": {},
   "source": [
    "### Verifica√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1293e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>min_date</th>\n",
       "      <th>max_date</th>\n",
       "      <th>n_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRENT</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBPUSD</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTCUSD</td>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>2025-10-31</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instr   min_date   max_date  n_rows\n",
       "0   BRENT 2025-04-04 2025-10-31     211\n",
       "1  GBPUSD 2025-04-04 2025-10-31     211\n",
       "2  BTCUSD 2025-04-04 2025-10-31     211"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = duckdb.connect(DUCKDB_PATH)\n",
    "\n",
    "con.execute(\"select instr, min(date) as min_date, max(date) as max_date, count(*) as n_rows from prices group by instr\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c29520",
   "metadata": {},
   "source": [
    "## Tabela intrumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7240f045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  instr_id              symbol                           name      class\n",
      "0    BRENT        DCOILBRENTEU                   Brent (FRED)  commodity\n",
      "1   GBPUSD  DEXUSUK (inverted)  GBP/USD (from DEXUSUK ‚Äì FRED)         fx\n",
      "2   BTCUSD   CoinGecko BTC/USD            Bitcoin (CoinGecko)     crypto\n"
     ]
    }
   ],
   "source": [
    "# --- 3¬™ tabela: instruments ---\n",
    "con.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS instruments (\n",
    "    instr_id VARCHAR PRIMARY KEY,\n",
    "    symbol   VARCHAR,\n",
    "    name     VARCHAR,\n",
    "    class    VARCHAR\n",
    ");\n",
    "\"\"\")\n",
    "con.register(\"tmp_instr\", pd.DataFrame([\n",
    "    {\"instr_id\":\"BRENT\",  \"symbol\":\"DCOILBRENTEU\",      \"name\":\"Brent (FRED)\",                  \"class\":\"commodity\"},\n",
    "    {\"instr_id\":\"GBPUSD\", \"symbol\":\"DEXUSUK (inverted)\",\"name\":\"GBP/USD (from DEXUSUK ‚Äì FRED)\", \"class\":\"fx\"},\n",
    "    {\"instr_id\":\"BTCUSD\", \"symbol\":\"CoinGecko BTC/USD\", \"name\":\"Bitcoin (CoinGecko)\",           \"class\":\"crypto\"},\n",
    "]))\n",
    "con.execute(\"DELETE FROM instruments WHERE instr_id IN (SELECT instr_id FROM tmp_instr)\")\n",
    "con.execute(\"INSERT INTO instruments SELECT * FROM tmp_instr\")\n",
    "\n",
    "print(con.execute(\"SELECT * FROM instruments\").df())\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec70a7",
   "metadata": {},
   "source": [
    "## Banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f1de6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          name\n",
      "0  instruments\n",
      "1     news_bbc\n",
      "2       prices\n",
      "  column_name column_type null   key default extra\n",
      "0        date        DATE  YES  None    None  None\n",
      "1       close      DOUBLE  YES  None    None  None\n",
      "2       instr     VARCHAR  YES  None    None  None\n",
      "    column_name column_type null   key default extra\n",
      "0         title     VARCHAR  YES  None    None  None\n",
      "1           url     VARCHAR  YES  None    None  None\n",
      "2       summary     VARCHAR  YES  None    None  None\n",
      "3  collected_at   TIMESTAMP  YES  None    None  None\n",
      "  column_name column_type null   key default extra\n",
      "0    instr_id     VARCHAR   NO   PRI    None  None\n",
      "1      symbol     VARCHAR  YES  None    None  None\n",
      "2        name     VARCHAR  YES  None    None  None\n",
      "3       class     VARCHAR  YES  None    None  None\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(DUCKDB_PATH)\n",
    "\n",
    "# lista todas as tabelas\n",
    "print(con.execute(\"SHOW TABLES\").df())\n",
    "\n",
    "# mostra o esquema completo (colunas e tipos)\n",
    "print(con.execute(\"DESCRIBE prices\").df())\n",
    "print(con.execute(\"DESCRIBE news_bbc\").df())\n",
    "print(con.execute(\"DESCRIBE instruments\").df())\n",
    "\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
